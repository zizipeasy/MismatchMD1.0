# -*- coding: utf-8 -*-
"""Code with Visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pdEnp_Te1xUIym26vS8qsmiK7J_DX6PJ
"""

import requests
from bs4 import BeautifulSoup
from googlesearch import search
import time

class MedicalMismatchDetector:

    #Remove duplicate results
    def deduplicate_results(results):
        seen_urls = set()
        seen_titles = set()
        unique_results = []

        for result in results:
            title_start = result.find("[From: ") + 7
            title_end = result.find("]", title_start)
            title = result[title_start:title_end].strip()

            url_start = result.find("[URL: ") + 6
            url_end = result.find("]", url_start)
            url = result[url_start:url_end].strip()

            if url not in seen_urls and title not in seen_titles:
                seen_urls.add(url)
                seen_titles.add(title)
                unique_results.append(result)

        return unique_results


    # Get information from Google
    def get_diagnosis_from_google(symptoms):
        diagnoses = []
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                          'AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/91.0.4472.124 Safari/537.36'
        }

        try:
            search_query = f"self {symptoms} diagnosis"

            for i, url in enumerate(search(search_query, num=30, stop=30, pause=2)):
                try:
                    response = requests.get(url, headers=headers, timeout=5)
                    response.raise_for_status()
                    soup = BeautifulSoup(response.content, "html.parser")
                    source_title = soup.title.string.strip() if soup.title else "Untitled"

                    for p in soup.find_all("p"):
                        text = p.get_text().strip()
                        if "diagnosis" in text.lower() or "condition" in text.lower():
                            formatted = f"[From: {source_title}]\n{text[:500]}\n[URL: {url}]"
                            diagnoses.append(formatted)
                except Exception as e:
                    print(f"Error processing {url}: {str(e)}")
                    continue

        except Exception as e:
            print(f"Search error: {str(e)}")

        return MedicalMismatchDetector.deduplicate_results(diagnoses)[:10]

    # Get information from PubMed
    def get_diagnosis_from_pubmed(symptoms):
        results = []
        try:
            base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': f"self {symptoms} diagnosis",
                'retmode': 'json',
                'retmax': 20
            }

            response = requests.get(base_url, params=params, timeout=10)
            data = response.json()
            idlist = data.get('esearchresult', {}).get('idlist', [])

            if not idlist:
                print("No PubMed results found.")
                return []

            # Batch summary request
            summary_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
            summary_params = {
                'db': 'pubmed',
                'id': ','.join(idlist),
                'retmode': 'json'
            }

            summary_response = requests.get(summary_url, params=summary_params, timeout=10)
            summary_data = summary_response.json()

            missing_ids = []
            for pmid in idlist:
                article = summary_data.get('result', {}).get(pmid)
                if not article:
                    missing_ids.append(pmid)
                    continue

                title = article.get('title', 'No title available')
                authors = ', '.join(a.get('name', '') for a in article.get('authors', []))
                journal = article.get('source', 'Unknown journal')

                formatted = (
                    f"[From: {title}]\n"
                    f"Authors: {authors}\n"
                    f"Journal: {journal}\n"
                    f"[URL: https://pubmed.ncbi.nlm.nih.gov/{pmid}/]"
                )
                results.append(formatted)

            print(f"\n Articles from PubMed.")
            if missing_ids:
                print(f" Missing summaries for: {', '.join(missing_ids)}")

        except Exception as e:
            print(f"PubMed search error: {str(e)}")

        return results[:10]


if __name__ == "__main__":
    user_symptoms = MedicalMismatchDetector.get_user_input()

    # Google Search
    google_results = MedicalMismatchDetector.get_diagnosis_from_google(user_symptoms)
    if google_results:
        print("\nGeneral Diagnoses (based on Google search results):")
        for i, res in enumerate(google_results, 1):
            print(f"\nResult {i}:\n{res}\n")
    else:
        print("No relevant Google results found.")

    # PubMed Search
    pubmed_results = MedicalMismatchDetector.get_diagnosis_from_pubmed(user_symptoms)
    if pubmed_results:
        print("\nMedical Source (based on PubMed search results):")
        for i, res in enumerate(pubmed_results, 1):
            print(f"\nResult {i}:\n{res}\n")
    else:
        print("No relevant PubMed results found.")